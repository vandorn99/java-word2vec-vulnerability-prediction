from scipy import spatial

import numpy as np
import array

from cpython cimport array

cimport numpy as np

DTYPE = np.float32
ctypedef np.float32_t DTYPE_t

def get_line_vuln(tuple args, int features=100):
    cdef unicode line = args[0]
    cdef object vuln_model = args[1]
    cdef set vuln_index2word_set = args[2]
    cdef list line_vectors = args[3]
    cdef list known_vuln_lines = args[4]

    cdef double mini = 1
    cdef unicode reason = u""
    cdef np.ndarray vec
    cdef double curr
    cdef Py_ssize_t i = 0
    cdef Py_ssize_t loop_length =  len(line_vectors)
    cdef np.ndarray line_vec = avg_feature_vector(line, vuln_model, features, vuln_index2word_set)
    line = line.strip()
    if len(line) < 2 or line.startswith(u"*") or line.startswith(u"//") or line.startswith(u"import") or line.startswith(u"package") or line == u"/**" or line[0] == u"@":
        return (mini, reason)

    # for vec, iter_line in zip(line_vectors, known_vuln_lines):
    while i < loop_length:
        curr = spatial.distance.cosine(line_vec, line_vectors[i])
        if curr < mini:
            mini = curr
            reason = known_vuln_lines[i]
        i += 1
    return (mini,reason)

cpdef np.ndarray avg_feature_vector(unicode sentence, object model, int num_features, set index2word_set):

    cdef list words = []
    cdef int n_words = 0
    cdef unicode word
    words = sentence.split()
    cdef np.ndarray feature_vec = np.zeros((num_features, ), dtype=DTYPE)
    for word in words:
        if word in index2word_set:
            n_words += 1
            feature_vec = np.add(feature_vec, model[word])
    if (n_words > 0):
        feature_vec = np.divide(feature_vec, n_words)
    return feature_vec
import os
import json
import csv
import argparse
import subprocess

import pandas as pd

from sklearn import linear_model

parser = argparse.ArgumentParser()
parser.add_argument('-m', '--model', metavar='', help='Which model\'s results should be parsed')
parser.add_argument('-a', '--aggregate', action='store_true', help='Whether to create aggregated data or not')
parser.add_argument('-r', '--regression', action='store_true', help='Create linear regression model')
parser.add_argument('-p', '--process_patches', action='store_true', help='Process patches')
parser.add_argument('-f', '--fold', action='store_true', help='Process k-fold results')
args = parser.parse_args()

model_stats = dict()


def process_model(model, rules, acceptances, no_zero=True, fold_num=1, result=1):
    model_name = model if not args.fold else f'fold_{fold_num}'
    model_stats[model_name] = dict()

    process_path = f'./{model}_results' if not args.fold else f'../fold_data/{fold_num}/results_{result}'

    for root, dirs, files in os.walk(process_path):
        for file in files:
            stats = dict()
            path = os.path.join(root, file)
            parts = path.split(os.sep)

            project_hash = str(parts[1])
            file_name_long = str(parts[-3])
            file_name_long = file_name_long.split('.java')[0] + '.java'
            file_name = str(file_name_long.split('_')[-1])
            percentage = str(parts[-2])
            rule = str(parts[-1]).split('.')[0]

            if percentage not in acceptances:
                continue

            if no_zero and percentage == '0%':
                continue

            if rules is not None and rule not in rules:
                continue

            with open(f'./filtered_files/{project_hash}/{file_name_long}/filtered.java', 'r') as f:
                original = list()
                for line in f.readlines():
                    if len(line.strip()) > 0:
                        original.append(line.strip())

            with open(path, 'r') as f:
                tmp = csv.DictReader(f)
                out = list()
                for row in tmp:
                    line = row['Line_content'].strip()
                    if len(line) > 1 and 'import' not in line and 'package' not in line and not line.startswith('//') and not line.startswith('/*') and not line.startswith('*/') and not line.startswith('*'):
                        out.append(line)

            with open(f'./patches/{project_hash}/{file_name_long}/{file_name}.txt', 'r') as f:
                patch = list()
                for line in f.readlines():
                    if len(line) > 0:
                        patch.append(line.strip())

            stats['file_lines'] = len(original)
            stats['flagged_lines'] = len(out)
            stats['vuln_lines'] = len(patch)

            flagged_vuln_lines = 0
            for vuln in patch:
                if vuln in out:
                    flagged_vuln_lines += 1

            stats['flagged_vuln_lines'] = flagged_vuln_lines

            stats['%_flagged'] = stats['flagged_lines'] * 100 / stats['file_lines']
            stats['%_is_vuln'] = stats['flagged_vuln_lines'] * 100 / stats['flagged_lines'] if stats['flagged_lines'] > 0 else 0
            stats['%_vuln_flagged'] = stats['flagged_vuln_lines'] * 100 / stats['vuln_lines'] if stats['vuln_lines'] > 0 else 0

            if model_stats.get(model_name).get(rule) is None:
                model_stats[model_name][rule] = dict()

            if model_stats.get(model_name).get(rule).get(file_name) is None:
                model_stats[model_name][rule][file_name] = dict()

            if model_stats.get(model_name).get(rule).get(file_name).get(percentage) is None:
                model_stats[model_name][rule][file_name][percentage] = stats

    if not model_stats[model_name]:
        model_stats.pop(model_name)


def create_table():
    file_name = 'result'

    if args.fold:
        file_name += '_kfold'

    if args.aggregate:
        file_name += '_aggregated'

    with open(file_name + '.csv', 'w') as f:
        line = ',,'

        for model in model_stats.keys():
            for rule in model_stats[model].keys():
                for file in model_stats[model][rule].keys():

                    if args.aggregate:
                        line += ',percentage'
                    else:
                        line += ',' + file

                    for i in range(len(model_stats[model][rule][file]) - 1):
                        line += ','

                    if args.aggregate:
                        break

                line += '\n'
                f.write(line)
                line = ',,'
                for file in model_stats[model][rule].keys():
                    for percentage in model_stats[model][rule][file].keys():
                        line += ',' + percentage

                    if args.aggregate:
                        break

                line += '\n'
                f.write(line)

                break
            break

        for model in model_stats.keys():
            line_file_lines = model
            line_flagged_lines = ','
            line_vuln_lines = ','
            line_flagged_vuln_lines = ','
            line_p_flagged = ','
            line_p_is_vuln = ','
            line_p_vuln_flagged = ','

            needs_header = True

            percentage_data = dict()

            for rule in model_stats[model].keys():
                for file in model_stats[model][rule].keys():
                    for percentage in model_stats[model][rule][file].keys():
                        if needs_header:
                            line_file_lines += ',' + rule + ',file_lines'
                            line_flagged_lines += ',' + 'flagged_lines'
                            line_vuln_lines += ',' + 'vuln_lines'
                            line_flagged_vuln_lines += ',' + 'flagged_vuln_lines'
                            line_p_flagged += ',' + '%_flagged'
                            line_p_is_vuln += ',' + '%_is_vuln'
                            line_p_vuln_flagged += ',' + '%_vuln_flagged'

                        if args.aggregate:
                            if percentage_data.get(percentage) is None:
                                percentage_data[percentage] = dict()
                                percentage_data[percentage]['file_lines'] = 0
                                percentage_data[percentage]['flagged_lines'] = 0
                                percentage_data[percentage]['vuln_lines'] = 0
                                percentage_data[percentage]['flagged_vuln_lines'] = 0
                                percentage_data[percentage]['num_records'] = 0

                            percentage_data[percentage]['file_lines'] += model_stats[model][rule][file][percentage]['file_lines']
                            percentage_data[percentage]['flagged_lines'] += model_stats[model][rule][file][percentage]['flagged_lines']
                            percentage_data[percentage]['vuln_lines'] += model_stats[model][rule][file][percentage]['vuln_lines']
                            percentage_data[percentage]['flagged_vuln_lines'] += model_stats[model][rule][file][percentage]['flagged_vuln_lines']
                            percentage_data[percentage]['num_records'] += 1

                        else:
                            line_file_lines += ',' + str(model_stats[model][rule][file][percentage]['file_lines'])
                            line_flagged_lines += ',' + str(model_stats[model][rule][file][percentage]['flagged_lines'])
                            line_vuln_lines += ',' + str(model_stats[model][rule][file][percentage]['vuln_lines'])
                            line_flagged_vuln_lines += ',' + str(model_stats[model][rule][file][percentage]['flagged_vuln_lines'])
                            line_p_flagged += ',' + str(model_stats[model][rule][file][percentage]['%_flagged'])
                            line_p_is_vuln += ',' + str(model_stats[model][rule][file][percentage]['%_is_vuln'])
                            line_p_vuln_flagged += ',' + str(model_stats[model][rule][file][percentage]['%_vuln_flagged'])

                        needs_header = False

                needs_header = True

                if args.aggregate:
                    for perc in percentage_data.keys():
                        line_p_flagged += ',' + str(percentage_data[perc]['flagged_lines'] * 100 / percentage_data[perc]['file_lines'])
                        line_p_is_vuln += ',' + str(percentage_data[perc]['flagged_vuln_lines'] * 100 / percentage_data[perc]['flagged_lines'] if percentage_data[perc]['flagged_lines'] > 0 else 0)
                        line_p_vuln_flagged += ',' + str(percentage_data[perc]['flagged_vuln_lines'] * 100 / percentage_data[perc]['vuln_lines'] if percentage_data[perc]['vuln_lines'] > 0 else 0)

                        '''
                        num_records = percentage_data[perc]['num_records']
                        percentage_data[perc]['file_lines'] /= num_records
                        percentage_data[perc]['flagged_lines'] /= num_records
                        percentage_data[perc]['vuln_lines'] /= num_records
                        percentage_data[perc]['flagged_vuln_lines'] /= num_records
                        '''

                        line_file_lines += ',' + str(percentage_data[perc]['file_lines'])
                        line_flagged_lines += ',' + str(percentage_data[perc]['flagged_lines'])
                        line_vuln_lines += ',' + str(percentage_data[perc]['vuln_lines'])
                        line_flagged_vuln_lines += ',' + str(percentage_data[perc]['flagged_vuln_lines'])

                line_file_lines += '\n'
                line_flagged_lines += '\n'
                line_vuln_lines += '\n'
                line_flagged_vuln_lines += '\n'
                line_p_flagged += '\n'
                line_p_is_vuln += '\n'
                line_p_vuln_flagged += '\n'

                f.write(line_file_lines)
                f.write(line_flagged_lines)
                f.write(line_vuln_lines)
                f.write(line_flagged_vuln_lines)
                f.write(line_p_flagged)
                f.write(line_p_is_vuln)
                f.write(line_p_vuln_flagged)

                line_file_lines = ''
                line_flagged_lines = ','
                line_vuln_lines = ','
                line_flagged_vuln_lines = ','
                line_p_flagged = ','
                line_p_is_vuln = ','
                line_p_vuln_flagged = ','

                percentage_data = dict()


def regression(model, acceptances):
    rules = ['rule_complex_and_surrounded.csv', 'rule_complex_before_surr.csv']

    data = dict()

    for rule in rules:
        data[rule] = dict()
        data[rule]['distance'] = list()
        data[rule]['surrounding'] = list()
        data[rule]['complexity'] = list()
        data[rule]['class'] = list()

    if not os.path.isdir(f'./{model}_results'):
        return

    for root, dirs, files in os.walk(f'./{model}_results'):
        for file in files:
            path = str(os.path.join(root, file))
            parts = path.split(os.sep)

            rule = parts[-1]
            percentage = parts[-2]

            if percentage not in acceptances or rule not in rules:
                continue

            patch = list()
            with open(f'./patches/{str(parts[1])}.txt', 'r') as f:
                for line in f.readlines():
                    patch.append(line.strip())

            with open(path, 'r') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    content = row['Line_content'].strip()
                    if content in patch:
                        data[rule]['class'].append(1)
                    else:
                        data[rule]['class'].append(0)

                    data[rule]['distance'].append(row['distance'])
                    data[rule]['surrounding'].append(row['surrounding'])
                    data[rule]['complexity'].append(row['complexity'])

    for rule in rules:
        df = pd.DataFrame(data[rule], columns=['distance', 'surrounding', 'complexity', 'class'])

        vuln_lines = df[df['class'] == 1]
        non_vuln_lines = df[df['class'] == 0]
        random_lines = non_vuln_lines.sample(n=len(vuln_lines))
        print(len(vuln_lines))

        vuln_lines = vuln_lines.append(random_lines)
        vuln_lines = vuln_lines.sample(frac=1)


        X = vuln_lines[['distance', 'surrounding', 'complexity']]
        y = vuln_lines['class']

        lmodel = linear_model.LinearRegression()
        lmodel.fit(X, y)

        out = dict()
        if os.path.exists('coeffs.json'):
            with open('coeffs.json', 'r') as f:
                out = json.load(f)

        with open('coeffs.json', 'w') as f:
            out[f'{model}_{rule}'] = f'{lmodel.intercept_} + {lmodel.coef_[0]}*distance + {lmodel.coef_[1]}*surrounding + {lmodel.coef_[2]}*complexity'
            json.dump(out, f, indent=4)


def process_patches():
    with open('./to_predict.json', 'r') as f:
        predict = json.load(f)

    for project in predict:
        for record in predict[project]:
            vuln_lines = record["vuln_lines"]
            for commit in vuln_lines:
                project_path = f'./patches/{project}_{commit.split(":")[0]}'

                if not os.path.exists(project_path):
                    os.mkdir(project_path)

                for file in vuln_lines[commit]:
                    parts = file.split('/')
                    file_name = parts[-1]

                    file_path = '_'.join(parts[-3:])

                    if not os.path.exists(f'{project_path}/{file_path}'):
                        os.mkdir(f'{project_path}/{file_path}')

                    with open(f'{project_path}/{file_path}/{file_name}.txt', 'w') as f:
                        for line in vuln_lines[commit][file]:
                            f.write(line + '\n')


def one_vuln_line():
    counter = 0
    total = 0
    for root, dirs, files in os.walk('processed_patches'):
        for file in files:
            total += 1
            with open(os.path.join(root, file), 'r') as f:
                data = json.load(f)
                if len(data['lines']) == 1:
                    counter += 1
    print(counter / total)


def process_kfold(rules, acceptances):
    for i in range(10):
        process_model(None, rules, acceptances, fold_num=(i+1))
    temp_stats = dict()
    num_folds = len(model_stats)

    for model in model_stats.keys():
        for rule in model_stats[model].keys():
            if temp_stats.get(rule) is None:
                temp_stats[rule] = dict()
            for file in model_stats[model][rule].keys():
                if temp_stats[rule].get('average') is None:
                    temp_stats[rule]['average'] = dict()
                for percentage in model_stats[model][rule][file].keys():
                    if temp_stats[rule]['average'].get(percentage) is None:
                        temp_stats[rule]['average'][percentage] = dict()
                        temp_stats[rule]['average'][percentage]['file_lines'] = 0
                        temp_stats[rule]['average'][percentage]['flagged_lines'] = 0
                        temp_stats[rule]['average'][percentage]['vuln_lines'] = 0
                        temp_stats[rule]['average'][percentage]['flagged_vuln_lines'] = 0
                        temp_stats[rule]['average'][percentage]['%_flagged'] = 0
                        temp_stats[rule]['average'][percentage]['%_is_vuln'] = 0
                        temp_stats[rule]['average'][percentage]['%_vuln_flagged'] = 0

                    temp_stats[rule]['average'][percentage]['file_lines'] += (model_stats[model][rule][file][percentage]['file_lines'] / num_folds)
                    temp_stats[rule]['average'][percentage]['flagged_lines'] += (model_stats[model][rule][file][percentage]['flagged_lines'] / num_folds)
                    temp_stats[rule]['average'][percentage]['vuln_lines'] += (model_stats[model][rule][file][percentage]['vuln_lines'] / num_folds)
                    temp_stats[rule]['average'][percentage]['flagged_vuln_lines'] += (model_stats[model][rule][file][percentage]['flagged_vuln_lines'] / num_folds)
                    temp_stats[rule]['average'][percentage]['%_flagged'] += (model_stats[model][rule][file][percentage]['%_flagged'] / num_folds)
                    temp_stats[rule]['average'][percentage]['%_is_vuln'] += (model_stats[model][rule][file][percentage]['%_is_vuln'] / num_folds)
                    temp_stats[rule]['average'][percentage]['%_vuln_flagged'] += (model_stats[model][rule][file][percentage]['%_vuln_flagged'] / num_folds)

    model_stats['AVERAGE'] = temp_stats


def main():
    if args.process_patches:
        process_patches()
    elif args.model:
        acceptances = ['75%', '80%', '85%', '90%', '95%']
        rules = ['no_rule', 'rule_no_one_word_lines', 'rule_check_surroundings', 'rule_prefer_complex', 'rule_complex_and_surrounded', 'rule_complex_before_surr', 'rule_iter_surrounding', 'rule_new_surrounded']

        if args.fold:
            process_kfold(rules, acceptances)
            create_table()
        else:
            with open(args.model, 'r') as f:
                for line in f.readlines():
                    if args.regression:
                        regression(line.strip(), acceptances)
                    else:
                        process_model(line.strip(), rules, acceptances)
                        create_table()
    else:
        one_vuln_line()


main()
